{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Mri4muSp-_J",
        "outputId": "8724b298-f1c4-4e4c-9316-c6cb6e4add9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INPUT: Solutions Architect with 6 years experience\n",
            "OUTPUT: {\n",
            "  \"role\": \"Solutions Architect\",\n",
            "  \"experience\": \"6 years\",\n",
            "  \"keywords\": [\n",
            "    \"Python\",\n",
            "    \"Java\",\n",
            "    \"C#\",\n",
            "    \".Net\",\n",
            "    \"Golang\",\n",
            "    \"Node\"\n",
            "  ]\n",
            "}\n",
            "{\n",
            "  \"role\": \"Solutions Architect\",\n",
            "  \"experience_raw\": {\n",
            "    \"start\": \"2018-04-03\",\n",
            "    \"end\": \"2024-04-03\"\n",
            "  },\n",
            "  \"skills_raw\": {\n",
            "    \"technical\": {\n",
            "      \"programming_languages\": [\n",
            "        {\n",
            "          \"name\": \"C++\",\n",
            "          \"level\": \"beginner\"\n",
            "        },\n",
            "        {\n",
            "          \"name\": \"Python\",\n",
            "          \"level\": \"intermediate\"\n",
            "        }\n",
            "      ],\n",
            "      \"frameworks\": [\n",
            "        {\n",
            "          \"name\": \"Vue\",\n",
            "          \"level\": \"beginner\"\n",
            "        },\n",
            "        {\n",
            "          \"name\": \"React\",\n",
            "          \"level\": \"intermediate\"\n",
            "        }\n",
            "      ],\n",
            "      \"databases\": [\n",
            "        {\n",
            "          \"name\": \"MongoDB\",\n",
            "          \"level\": \"intermediate\"\n",
            "        },\n",
            "        {\n",
            "          \"name\": \"Redis\",\n",
            "          \"level\": \"expert\"\n",
            "        }\n",
            "      ],\n",
            "      \"cloud\": [\n",
            "        {\n",
            "          \"name\": \"Azure\",\n",
            "          \"level\": \"expert\"\n",
            "        }\n",
            "      ]\n",
            "    },\n",
            "    \"languages\": [\n",
            "      {\n",
            "        \"name\": \"English\",\n",
            "        \"level\": \"fluent\"\n",
            "      }\n",
            "    ]\n",
            "  },\n",
            "  \"projects_raw\": [\n",
            "    {\n",
            "      \"name\": \"Solutions Architect Project\",\n",
            "      \"description\": \"Designed and implemented a comprehensive solution architecture for an enterprise system, improving system scalability and reliability.\",\n",
            "      \"technologies\": [\n",
            "        \"Git\",\n",
            "        \"C#\"\n",
            "      ],\n",
            "      \"role\": \"Solutions Architect\",\n",
            "      \"url\": \"https://berger.net/\",\n",
            "      \"impact\": \"Guess guy add value once one likely eight assume buy eight.\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Solutions Architect Project\",\n",
            "      \"description\": \"Designed and implemented a comprehensive solution architecture for an enterprise system, improving system scalability and reliability.\",\n",
            "      \"technologies\": [\n",
            "        \"Git\",\n",
            "        \"REST\",\n",
            "        \"C++\"\n",
            "      ],\n",
            "      \"role\": \"Solutions Architect\",\n",
            "      \"url\": \"https://www.roth.info/\",\n",
            "      \"impact\": \"Specific nice another often church recognize traditional raise raise prepare only off war million.\"\n",
            "    }\n",
            "  ],\n",
            "  \"tech_env_raw\": {\n",
            "    \"technologies\": [\n",
            "      \"Kubernetes\"\n",
            "    ],\n",
            "    \"methodologies\": [\n",
            "      \"Agile\"\n",
            "    ],\n",
            "    \"tools\": [\n",
            "      \"Docker\",\n",
            "      \"GitLab\",\n",
            "      \"Git\"\n",
            "    ]\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "def detect_domain(role):\n",
        "    role = role.lower()\n",
        "    for key, domain in ROLE_DOMAINS.items():\n",
        "        if key in role:\n",
        "            return domain\n",
        "    return \"general\"   # fallback\n",
        "\n",
        "\n",
        "def filter_keywords_by_domain(role, raw_keywords):\n",
        "    domain = detect_domain(role)\n",
        "    allowed = DOMAIN_KEYWORDS.get(domain, DOMAIN_KEYWORDS[\"general\"])\n",
        "\n",
        "    raw_norm = [(kw, kw.lower()) for kw in raw_keywords]\n",
        "\n",
        "    filtered = []\n",
        "    seen = set()\n",
        "\n",
        "    \n",
        "    for orig, low in raw_norm:\n",
        "        if low in allowed and low not in seen:\n",
        "            seen.add(low)\n",
        "            filtered.append(orig)\n",
        "\n",
        "    \n",
        "    if len(filtered) < 3:\n",
        "        needed = 3 - len(filtered)\n",
        "        for kw in allowed:\n",
        "            if kw not in seen:\n",
        "                filtered.append(kw.title())\n",
        "                seen.add(kw)\n",
        "                needed -= 1\n",
        "                if needed == 0:\n",
        "                    break\n",
        "\n",
        "    \n",
        "    while len(filtered) < 6:\n",
        "        for kw in allowed:\n",
        "            if kw not in seen:\n",
        "                filtered.append(kw.title())\n",
        "                seen.add(kw)\n",
        "                break\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    \n",
        "    return filtered[:6]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def load_resume(line_number, path=\"master_resumes.jsonl\"):\n",
        "   \n",
        "    with open(path, \"r\") as file:\n",
        "        line = None\n",
        "        for _ in range(line_number):\n",
        "            line = file.readline()\n",
        "            if not line:\n",
        "                break\n",
        "    if not line:\n",
        "        raise IndexError(f\"File has fewer than {line_number} lines.\")\n",
        "    return json.loads(line)\n",
        "\n",
        "\n",
        "\n",
        "def parse_date(date_str):\n",
        "    \n",
        "    if not date_str:\n",
        "        return None\n",
        "\n",
        "    cleaned = str(date_str).strip().lower()\n",
        "\n",
        "    if cleaned in [\"unknown\", \"n/a\", \"\", \"none\"]:\n",
        "        return None\n",
        "\n",
        "    if cleaned in [\"present\", \"current\", \"now\", \"today\"]:\n",
        "        return datetime.now()\n",
        "\n",
        "    for fmt in (\"%Y-%m-%d\", \"%Y-%m\", \"%Y\"):\n",
        "        try:\n",
        "            return datetime.strptime(cleaned, fmt)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "\n",
        "def is_valid_tech_role(role):\n",
        "    if not role:\n",
        "        return False\n",
        "    role = role.lower()\n",
        "    if \"advocate\" in role:\n",
        "        return False\n",
        "   \n",
        "    return True\n",
        "\n",
        "\n",
        "\n",
        "def normalize_token(tok):\n",
        "   \n",
        "    if not tok:\n",
        "        return None\n",
        "    tok = str(tok).strip()\n",
        "    tok = tok.strip(' .;')          \n",
        "    return tok if tok else None\n",
        "\n",
        "def split_commas(tok):\n",
        "   \n",
        "    if not tok:\n",
        "        return []\n",
        "    if isinstance(tok, str) and \",\" in tok:\n",
        "        parts = [p.strip() for p in tok.split(\",\") if p.strip()]\n",
        "        return parts\n",
        "    return [tok]\n",
        "\n",
        "\n",
        "\\\n",
        "def extract_keywords(resume, limit=6):\n",
        "    \n",
        "    seen = set()\n",
        "    ordered = []\n",
        "\n",
        "    def add_token(tok):\n",
        "        if not tok:\n",
        "            return\n",
        "        \n",
        "        for part in split_commas(tok):\n",
        "            clean = normalize_token(part)\n",
        "            if not clean:\n",
        "                continue\n",
        "            \n",
        "            key = clean.lower()\n",
        "            if key not in seen:\n",
        "                seen.add(key)\n",
        "                ordered.append(clean)\n",
        "\n",
        "   \n",
        "    skills = resume.get(\"skills\", {}).get(\"technical\", {})\n",
        "    for group in [\"programming_languages\", \"frameworks\", \"databases\", \"cloud\"]:\n",
        "        for item in skills.get(group, []):\n",
        "            if isinstance(item, dict):\n",
        "                add_token(item.get(\"name\"))\n",
        "            else:\n",
        "                add_token(item)\n",
        "\n",
        "\n",
        "    exps = resume.get(\"experience\", [])\n",
        "    if exps:\n",
        "        exp0 = exps[0]\n",
        "        tech_env = exp0.get(\"technical_environment\", {})\n",
        "        for group in [\"technologies\", \"tools\"]:\n",
        "            for item in tech_env.get(group, []):\n",
        "                add_token(item)\n",
        "\n",
        "   \n",
        "    for proj in resume.get(\"projects\", []):\n",
        "        for tech in proj.get(\"technologies\", []):\n",
        "            add_token(tech)\n",
        "\n",
        "   \n",
        "    return ordered[:limit]\n",
        "\n",
        "\n",
        "\n",
        "def build_example_from_resume(resume):\n",
        "   \n",
        "    if not resume or not resume.get(\"experience\"):\n",
        "        return None\n",
        "\n",
        "    exp0 = resume[\"experience\"][0]\n",
        "    role = exp0.get(\"title\", \"Unknown Role\").strip()\n",
        "    if not is_valid_tech_role(role):\n",
        "        return None\n",
        "\n",
        "    \n",
        "    start_raw = exp0.get(\"dates\", {}).get(\"start\")\n",
        "    end_raw   = exp0.get(\"dates\", {}).get(\"end\")\n",
        "\n",
        "    start_date = parse_date(start_raw)\n",
        "    end_date   = parse_date(end_raw)\n",
        "\n",
        "    if start_date and end_date:\n",
        "        days = (end_date - start_date).days\n",
        "        years = max(1, round(days / 365))\n",
        "    else:\n",
        "        level = exp0.get(\"level\", \"\").lower()\n",
        "        if level == \"junior\":\n",
        "            years = 1\n",
        "        elif level == \"mid\":\n",
        "            years = 3\n",
        "        elif level == \"senior\":\n",
        "            years = 6\n",
        "        else:\n",
        "            \n",
        "            years = 1\n",
        "\n",
        "    experience_str = f\"{years} years\"\n",
        "    input_str = f\"{role} with {years} years experience\"\n",
        "\n",
        "    keywords = extract_keywords(resume, limit=6)\n",
        "\n",
        "    raw_keywords = extract_keywords(resume)\n",
        "\n",
        "    clean_keywords = filter_keywords_by_domain(role, raw_keywords)\n",
        "\n",
        "    output = {\n",
        "      \"role\": role,\n",
        "      \"experience\": experience_str,\n",
        "      \"keywords\": clean_keywords\n",
        "        }\n",
        "\n",
        "\n",
        "    return {\"input\": input_str, \"output\": output}\n",
        "\n",
        "\n",
        "ROLE_DOMAINS = {\n",
        "    \"android\": \"mobile\",\n",
        "    \"ios\": \"mobile\",\n",
        "    \"mobile\": \"mobile\",\n",
        "\n",
        "    \"frontend\": \"web\",\n",
        "    \"backend\": \"web\",\n",
        "    \"full stack\": \"web\",\n",
        "    \"web\": \"web\",\n",
        "    \"react\": \"web\",\n",
        "    \"angular\": \"web\",\n",
        "    \"vue\": \"web\",\n",
        "    \"javascript\": \"web\",\n",
        "    \"node\": \"web\",\n",
        "\n",
        "    \"python\": \"backend\",\n",
        "    \"java\": \"backend\",\n",
        "    \"dotnet\": \"backend\",\n",
        "    \"c#\": \"backend\",\n",
        "    \".net\": \"backend\",\n",
        "\n",
        "    \"data\": \"data\",\n",
        "    \"database\": \"data\",\n",
        "    \"sql\": \"data\",\n",
        "    \"analyst\": \"data\",\n",
        "\n",
        "    \"ml\": \"ml\",\n",
        "    \"machine learning\": \"ml\",\n",
        "    \"deep learning\": \"ml\",\n",
        "    \"ai\": \"ml\",\n",
        "    \"nlp\": \"ml\",\n",
        "\n",
        "    \"security\": \"security\",\n",
        "    \"cyber\": \"security\",\n",
        "    \"network\": \"security\",\n",
        "\n",
        "    \"qa\": \"testing\",\n",
        "    \"tester\": \"testing\",\n",
        "    \"quality\": \"testing\",\n",
        "\n",
        "    \"devops\": \"devops\",\n",
        "    \"cloud\": \"cloud\",\n",
        "\n",
        "   \n",
        "    \"architect\": \"backend\",\n",
        "    \"engineer\": \"backend\",\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "DOMAIN_KEYWORDS = {\n",
        "    \"web\": [\n",
        "        \"javascript\", \"typescript\", \"react\", \"redux\", \"angular\", \"vue\",\n",
        "        \"html\", \"css\", \"sass\", \"bootstrap\",\n",
        "        \"node\", \"express\", \"django\", \"flask\",\n",
        "        \"webpack\", \"git\", \"next.js\", \"nuxt\", \"rest\", \"graphql\"\n",
        "    ],\n",
        "\n",
        "    \"mobile\": [\n",
        "        \"java\", \"kotlin\", \"android\", \"android studio\", \"gradle\", \"xml\",\n",
        "        \"retrofit\", \"sqlite\", \"jetpack\", \"compose\"\n",
        "    ],\n",
        "\n",
        "    \"backend\": [\n",
        "        \"python\", \"java\", \"c#\", \".net\", \"golang\", \"node\",\n",
        "        \"flask\", \"django\", \"spring\", \"postgresql\", \"mysql\",\n",
        "        \"rest\", \"graphql\", \"docker\"\n",
        "    ],\n",
        "\n",
        "    \"data\": [\n",
        "        \"sql\", \"mysql\", \"postgresql\", \"pandas\", \"numpy\",\n",
        "        \"etl\", \"data pipelines\", \"tableau\", \"powerbi\"\n",
        "    ],\n",
        "\n",
        "    \"ml\": [\n",
        "        \"tensorflow\", \"pytorch\", \"scikit\", \"keras\",\n",
        "        \"nlp\", \"transformers\", \"opencv\", \"huggingface\",\n",
        "        \"deep learning\", \"machine learning\"\n",
        "    ],\n",
        "\n",
        "    \"security\": [\n",
        "        \"networking\", \"vlan\", \"acl\", \"acls\", \"ids\", \"ips\",\n",
        "        \"firewall\", \"penetration testing\", \"pentest\",\n",
        "        \"vpn\", \"nat\", \"subnetting\", \"supernetting\", \"wireshark\"\n",
        "    ],\n",
        "\n",
        "    \"testing\": [\n",
        "        \"selenium\", \"pytest\", \"unittest\",\n",
        "        \"cypress\", \"jenkins\", \"jmeter\",\n",
        "        \"test automation\", \"qa\", \"ci/cd\"\n",
        "    ],\n",
        "\n",
        "    \"devops\": [\n",
        "        \"docker\", \"kubernetes\", \"helm\",\n",
        "        \"jenkins\", \"gitlab\", \"ci/cd\",\n",
        "        \"terraform\", \"ansible\", \"prometheus\", \"grafana\"\n",
        "    ],\n",
        "\n",
        "    \"cloud\": [\n",
        "        \"aws\", \"azure\", \"gcp\",\n",
        "        \"lambda\", \"s3\", \"cloudwatch\", \"ec2\"\n",
        "    ],\n",
        "\n",
        "    \"general\": [\n",
        "        \"git\", \"linux\", \"shell\", \"api\", \"rest\",\n",
        "        \"scrum\", \"agile\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "def get_raw_resume_info(resume):\n",
        "    info = {}\n",
        "\n",
        "    \n",
        "    if resume.get(\"experience\"):\n",
        "        info[\"role\"] = resume[\"experience\"][0].get(\"title\", None)\n",
        "    else:\n",
        "        info[\"role\"] = None\n",
        "\n",
        "    \n",
        "    if resume.get(\"experience\"):\n",
        "        dates = resume[\"experience\"][0].get(\"dates\", {})\n",
        "        info[\"experience_raw\"] = {\n",
        "            \"start\": dates.get(\"start\"),\n",
        "            \"end\": dates.get(\"end\")\n",
        "        }\n",
        "    else:\n",
        "        info[\"experience_raw\"] = None\n",
        "\n",
        "    \n",
        "    info[\"skills_raw\"] = resume.get(\"skills\", {})\n",
        "\n",
        "    \n",
        "    info[\"projects_raw\"] = resume.get(\"projects\", [])\n",
        "\n",
        "    \n",
        "    if resume.get(\"experience\"):\n",
        "        info[\"tech_env_raw\"] = resume[\"experience\"][0].get(\"technical_environment\", {})\n",
        "    else:\n",
        "        info[\"tech_env_raw\"] = None\n",
        "\n",
        "    return info\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    r = load_resume(4782)          \n",
        "    example = build_example_from_resume(r)\n",
        "    if example:\n",
        "        print(\"INPUT:\", example[\"input\"])\n",
        "        print(\"OUTPUT:\", json.dumps(example[\"output\"], indent=2))\n",
        "    else:\n",
        "        print(\"Resume #42 skipped (non-tech or incomplete).\")\n",
        "\n",
        "    raw_info = get_raw_resume_info(r)\n",
        "\n",
        "    print(json.dumps(raw_info, indent=2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7E7CjrsCq_w",
        "outputId": "f7c90a52-890f-4a02-8c14-98f65538258b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adjunct Faculty & Data Scientist\n",
            "Advocate\n",
            "Ai Engineer\n",
            "Android Developer\n",
            "Angular Developer\n",
            "Automation Engineer\n",
            "Backend Developer\n",
            "Blockchain Developer\n",
            "Business Analyst\n",
            "Cloud Engineer\n",
            "Cloud Operations Architect (DevOps)\n",
            "Computer Vision Engineer\n",
            "Cybersecurity Engineer\n",
            "Data Engineer\n",
            "Data Science Consultant\n",
            "Data Scientist\n",
            "Database Administrator\n",
            "Database Engineer\n",
            "Deep Learning Engineer\n",
            "DevOps Engineer\n",
            "Devops Engineer\n",
            "Electrical Engineer\n",
            "Embedded Systems Engineer\n",
            "Flutter Developer\n",
            "Frontend Developer\n",
            "Full Stack Developer\n",
            "Information Security Analyst\n",
            "Infrastructure Engineer\n",
            "Ios Developer\n",
            "Java Developer\n",
            "Java Web Developer\n",
            "Javascript Developer\n",
            "Jr. Java Developer\n",
            "Kubernetes Engineer\n",
            "Machine Learning Engineer\n",
            "Machine Learning Engineer Intern\n",
            "Mlops Engineer\n",
            "Mobile Developer\n",
            "Network Security Engineer\n",
            "Network and Security Engineer\n",
            "Nlp Engineer\n",
            "Node.Js Developer\n",
            "Nosql Developer\n",
            "Operations Manager\n",
            "Penetration Tester\n",
            "Platform Engineer\n",
            "Project Manager\n",
            "Python API Developer\n",
            "Python Developer\n",
            "Python Developer/analyst\n",
            "Python RESTful API Developer\n",
            "Python RESTful API developer\n",
            "Qa Engineer\n",
            "React Developer\n",
            "React Native Developer\n",
            "SAP Technical Architect\n",
            "Security Engineer\n",
            "Senior Business Analyst - RPA\n",
            "Site Reliability Engineer\n",
            "Software Engineer\n",
            "Software Testing & Automation Engineer\n",
            "Solutions Architect\n",
            "Sql Developer\n",
            "Systems Engineer\n",
            "Technical Architect\n",
            "Vue Developer\n",
            "Web Developer\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "roles = set()\n",
        "\n",
        "with open(\"master_resumes.jsonl\", \"r\") as file:\n",
        "    for line in file:\n",
        "        if not line.strip():\n",
        "            continue\n",
        "\n",
        "        resume = json.loads(line)\n",
        "\n",
        "        \n",
        "        experience = resume.get(\"experience\", [])\n",
        "        if not experience:\n",
        "            continue\n",
        "\n",
        "        \n",
        "        title = experience[0].get(\"title\", \"\").strip()\n",
        "\n",
        "        if title:\n",
        "            roles.add(title)\n",
        "\n",
        "\n",
        "for r in sorted(roles):\n",
        "    print(r)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvBYUrp9Da0q",
        "outputId": "742b10f7-cd14-49c1-e35c-2a80bfeed520"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total resumes loaded: 4817\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "def load_all_resumes(path):\n",
        "    resumes = []\n",
        "    with open(path, \"r\") as file:\n",
        "        for line in file:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            try:\n",
        "                resumes.append(json.loads(line))\n",
        "            except:\n",
        "                pass\n",
        "    return resumes\n",
        "\n",
        "\n",
        "resumes = load_all_resumes(\"master_resumes.jsonl\")\n",
        "\n",
        "print(\"Total resumes loaded:\", len(resumes))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "467_iTAAsag2",
        "outputId": "61f45d23-24da-497d-9c8a-7872963cc66b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INPUT: Web Developer with 4 years experience\n",
            "OUTPUT: {\n",
            "  \"role\": \"Web Developer\",\n",
            "  \"experience\": \"4 years\",\n",
            "  \"keywords\": [\n",
            "    \"Ruby\",\n",
            "    \"JavaScript\",\n",
            "    \"Django\",\n",
            "    \"MongoDB\",\n",
            "    \"Redis\",\n",
            "    \"Google Cloud\",\n",
            "    \"Kubernetes\",\n",
            "    \"Git\",\n",
            "    \"Jenkins\",\n",
            "    \"Python\",\n",
            "    \"CI/CD\"\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "def load_resume(line_number, path=\"master_resumes.jsonl\"):\n",
        "    \n",
        "    with open(path, \"r\") as file:\n",
        "        line = None\n",
        "        for _ in range(line_number):\n",
        "            line = file.readline()\n",
        "            if not line:\n",
        "                break\n",
        "    if not line:\n",
        "        raise IndexError(f\"File has fewer than {line_number} lines.\")\n",
        "    return json.loads(line)\n",
        "\n",
        "\n",
        "\n",
        "def parse_date(date_str):\n",
        "    if not date_str:\n",
        "        return None\n",
        "\n",
        "    cleaned = str(date_str).strip().lower()\n",
        "\n",
        "    if cleaned in [\"unknown\", \"n/a\", \"\", \"none\"]:\n",
        "        return None\n",
        "\n",
        "    if cleaned in [\"present\", \"current\", \"now\", \"today\"]:\n",
        "        return datetime.now()\n",
        "\n",
        "    for fmt in (\"%Y-%m-%d\", \"%Y-%m\", \"%Y\"):\n",
        "        try:\n",
        "            return datetime.strptime(cleaned, fmt)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "\n",
        "def is_valid_tech_role(role):\n",
        "    if not role:\n",
        "        return False\n",
        "    role = role.lower()\n",
        "    if \"advocate\" in role:\n",
        "        return False\n",
        "    \n",
        "    return True\n",
        "\n",
        "\n",
        "\n",
        "def normalize_token(tok):\n",
        "    if not tok:\n",
        "        return None\n",
        "    tok = str(tok).strip()\n",
        "    tok = tok.strip(' .;')          \n",
        "    return tok if tok else None\n",
        "\n",
        "def split_commas(tok):\n",
        "    if not tok:\n",
        "        return []\n",
        "    if isinstance(tok, str) and \",\" in tok:\n",
        "        parts = [p.strip() for p in tok.split(\",\") if p.strip()]\n",
        "        return parts\n",
        "    return [tok]\n",
        "\n",
        "\n",
        "\n",
        "def extract_keywords(resume):\n",
        "\n",
        "    seen = set()\n",
        "    ordered = []\n",
        "\n",
        "    def add_token(tok):\n",
        "        if not tok:\n",
        "            return\n",
        "        for part in split_commas(tok):\n",
        "            clean = normalize_token(part)\n",
        "            if not clean:\n",
        "                continue\n",
        "            key = clean.lower()\n",
        "            if key not in seen:\n",
        "                seen.add(key)\n",
        "                ordered.append(clean)\n",
        "\n",
        "\n",
        "    skills = resume.get(\"skills\", {}).get(\"technical\", {})\n",
        "    for group in [\"programming_languages\", \"frameworks\", \"databases\", \"cloud\"]:\n",
        "        for item in skills.get(group, []):\n",
        "            if isinstance(item, dict):\n",
        "                add_token(item.get(\"name\"))\n",
        "            else:\n",
        "                add_token(item)\n",
        "\n",
        "    \n",
        "    for exp in resume.get(\"experience\", []):\n",
        "        tech_env = exp.get(\"technical_environment\", {})\n",
        "        for group in [\"technologies\", \"tools\"]:\n",
        "            for item in tech_env.get(group, []):\n",
        "                add_token(item)\n",
        "\n",
        "   \n",
        "    for proj in resume.get(\"projects\", []):\n",
        "        for item in proj.get(\"technologies\", []):\n",
        "            add_token(item)\n",
        "\n",
        "    return ordered\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def build_example_from_resume(resume):\n",
        "    if not resume or not resume.get(\"experience\"):\n",
        "        return None\n",
        "\n",
        "    exp0 = resume[\"experience\"][0]\n",
        "    role = exp0.get(\"title\", \"Unknown Role\").strip()\n",
        "    if not is_valid_tech_role(role):\n",
        "        return None\n",
        "\n",
        "    start_raw = exp0.get(\"dates\", {}).get(\"start\")\n",
        "    end_raw   = exp0.get(\"dates\", {}).get(\"end\")\n",
        "\n",
        "    start_date = parse_date(start_raw)\n",
        "    end_date   = parse_date(end_raw)\n",
        "\n",
        "    if start_date and end_date:\n",
        "        days = (end_date - start_date).days\n",
        "        years = max(1, round(days / 365))\n",
        "    else:\n",
        "        level = exp0.get(\"level\", \"\").lower()\n",
        "        if level == \"junior\":\n",
        "            years = 1\n",
        "        elif level == \"mid\":\n",
        "            years = 3\n",
        "        elif level == \"senior\":\n",
        "            years = 6\n",
        "        else:\n",
        "            \n",
        "            years = 1\n",
        "\n",
        "    experience_str = f\"{years} years\"\n",
        "    input_str = f\"{role} with {years} years experience\"\n",
        "\n",
        "    keywords = extract_keywords(resume)\n",
        "\n",
        "    output = {\n",
        "        \"role\": role,\n",
        "        \"experience\": experience_str,\n",
        "        \"keywords\": keywords\n",
        "    }\n",
        "\n",
        "    return {\"input\": input_str, \"output\": output}\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    r = load_resume(1569)          # 1-based: 1 => first line\n",
        "    example = build_example_from_resume(r)\n",
        "    if example:\n",
        "        print(\"INPUT:\", example[\"input\"])\n",
        "        print(\"OUTPUT:\", json.dumps(example[\"output\"], indent=2))\n",
        "    else:\n",
        "        print(\"Resume #42 skipped (non-tech or incomplete).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXElQ1_CtJXG",
        "outputId": "38ec4af5-4a4b-4ab7-994d-81da6650ccf6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DONE — final_clean_dataset.jsonl created successfully!\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "def load_resume(line_number, path=\"master_resumes.jsonl\"):\n",
        "    with open(path, \"r\") as file:\n",
        "        line = None\n",
        "        for _ in range(line_number):\n",
        "            line = file.readline()\n",
        "            if not line:\n",
        "                break\n",
        "    if not line:\n",
        "        raise IndexError(f\"File has fewer than {line_number} lines.\")\n",
        "    return json.loads(line)\n",
        "\n",
        "\n",
        "\n",
        "def load_all_resumes(path=\"master_resumes.jsonl\"):\n",
        "    resumes = []\n",
        "    with open(path, \"r\") as file:\n",
        "        for line in file:\n",
        "            try:\n",
        "                resumes.append(json.loads(line))\n",
        "            except:\n",
        "                pass\n",
        "    return resumes\n",
        "\n",
        "\n",
        "\n",
        "def parse_date(date_str):\n",
        "    if not date_str:\n",
        "        return None\n",
        "    cleaned = str(date_str).strip().lower()\n",
        "    if cleaned in [\"unknown\", \"n/a\", \"\", \"none\"]:\n",
        "        return None\n",
        "    if cleaned in [\"present\", \"current\", \"now\", \"today\"]:\n",
        "        return datetime.now()\n",
        "    for fmt in (\"%Y-%m-%d\", \"%Y-%m\", \"%Y\"):\n",
        "        try:\n",
        "            return datetime.strptime(cleaned, fmt)\n",
        "        except:\n",
        "            pass\n",
        "    return None\n",
        "\n",
        "\n",
        "\n",
        "def is_valid_tech_role(role):\n",
        "    if not role:\n",
        "        return False\n",
        "    if \"advocate\" in role.lower():\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "\n",
        "def normalize_token(tok):\n",
        "    if not tok:\n",
        "        return None\n",
        "    tok = str(tok).strip().strip(\" .;\")\n",
        "    return tok or None\n",
        "\n",
        "\n",
        "def split_commas(tok):\n",
        "    if not tok:\n",
        "        return []\n",
        "    if isinstance(tok, str) and \",\" in tok:\n",
        "        return [p.strip() for p in tok.split(\",\") if p.strip()]\n",
        "    return [tok]\n",
        "\n",
        "\n",
        "\n",
        "def extract_keywords(resume):\n",
        "    seen = set()\n",
        "    ordered = []\n",
        "\n",
        "    def add(tok):\n",
        "        if not tok:\n",
        "            return\n",
        "        for part in split_commas(tok):\n",
        "            clean = normalize_token(part)\n",
        "            if clean:\n",
        "                key = clean.lower()\n",
        "                if key not in seen:\n",
        "                    seen.add(key)\n",
        "                    ordered.append(clean)\n",
        "\n",
        "    skills = resume.get(\"skills\", {}).get(\"technical\", {})\n",
        "    for group in [\"programming_languages\", \"frameworks\", \"databases\", \"cloud\"]:\n",
        "        for item in skills.get(group, []):\n",
        "            if isinstance(item, dict):\n",
        "                add(item.get(\"name\"))\n",
        "            else:\n",
        "                add(item)\n",
        "\n",
        "    for exp in resume.get(\"experience\", []):\n",
        "        tech_env = exp.get(\"technical_environment\", {})\n",
        "        for group in [\"technologies\", \"tools\"]:\n",
        "            for item in tech_env.get(group, []):\n",
        "                add(item)\n",
        "\n",
        " \n",
        "    for proj in resume.get(\"projects\", []):\n",
        "        for tech in proj.get(\"technologies\", []):\n",
        "            add(tech)\n",
        "\n",
        "    return ordered\n",
        "\n",
        "\n",
        "\n",
        "def build_example_from_resume(resume):\n",
        "    if not resume or not resume.get(\"experience\"):\n",
        "        return None\n",
        "\n",
        "    exp0 = resume[\"experience\"][0]\n",
        "    role = exp0.get(\"title\", \"\").strip()\n",
        "\n",
        "    if not is_valid_tech_role(role):\n",
        "        return None\n",
        "\n",
        "  \n",
        "    date_info = exp0.get(\"dates\", {})\n",
        "    start = parse_date(date_info.get(\"start\"))\n",
        "    end = parse_date(date_info.get(\"end\"))\n",
        "\n",
        "    if start and end:\n",
        "        delta_days = (end - start).days\n",
        "        years = max(1, round(delta_days / 365))\n",
        "    else:\n",
        "        level = exp0.get(\"level\", \"\").lower()\n",
        "        years = {\"junior\": 1, \"mid\": 3, \"senior\": 6}.get(level, 1)\n",
        "\n",
        "    experience_str = f\"{years} years\"\n",
        "    input_str = f\"{role} with {years} years experience\"\n",
        "\n",
        "    keywords = extract_keywords(resume)\n",
        "\n",
        "    return {\n",
        "        \"input\": input_str,\n",
        "        \"output\": {\n",
        "            \"role\": role,\n",
        "            \"experience\": experience_str,\n",
        "            \"keywords\": keywords\n",
        "        }\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "def normalize_role(role):\n",
        "    role = role.strip().lower()\n",
        "    while \"  \" in role:\n",
        "        role = role.replace(\"  \", \" \")\n",
        "    return role\n",
        "\n",
        "\n",
        "def extract_years(exp_str):\n",
        "    for token in exp_str.split():\n",
        "        if token.isdigit():\n",
        "            return int(token)\n",
        "    return None\n",
        "\n",
        "\n",
        "def make_key(example):\n",
        "    role = normalize_role(example[\"output\"][\"role\"])\n",
        "    years = extract_years(example[\"output\"][\"experience\"])\n",
        "    return (role, years)\n",
        "\n",
        "\n",
        "def merge_keywords(list1, list2):\n",
        "    seen = set()\n",
        "    merged = []\n",
        "    for item in list1 + list2:\n",
        "        key = item.strip().lower()\n",
        "        if key not in seen:\n",
        "            seen.add(key)\n",
        "            merged.append(item)\n",
        "    return merged\n",
        "\n",
        "\n",
        "def dedupe_and_merge(examples):\n",
        "    result = {}\n",
        "    for ex in examples:\n",
        "        key = make_key(ex)\n",
        "        if key not in result:\n",
        "            result[key] = ex\n",
        "        else:\n",
        "            old_kw = result[key][\"output\"][\"keywords\"]\n",
        "            new_kw = ex[\"output\"][\"keywords\"]\n",
        "            result[key][\"output\"][\"keywords\"] = merge_keywords(old_kw, new_kw)\n",
        "    return list(result.values())\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    resumes = load_all_resumes(\"master_resumes.jsonl\")\n",
        "\n",
        "    all_examples = []\n",
        "    for r in resumes:\n",
        "        ex = build_example_from_resume(r)\n",
        "        if ex:\n",
        "            all_examples.append(ex)\n",
        "\n",
        "    final_dataset = dedupe_and_merge(all_examples)\n",
        "\n",
        "    with open(\"final_clean_dataset.jsonl\", \"w\") as f:\n",
        "        for item in final_dataset:\n",
        "            f.write(json.dumps(item) + \"\\n\")\n",
        "\n",
        "    print(\"DONE — final_clean_dataset.jsonl created successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzVKJQWxB_qe",
        "outputId": "935fd9ef-fe08-4a63-c2e2-accb3270af1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "adjunct faculty & data scientist\n",
            "ai engineer\n",
            "android developer\n",
            "angular developer\n",
            "automation engineer\n",
            "backend developer\n",
            "blockchain developer\n",
            "cloud engineer\n",
            "cloud operations architect (devops)\n",
            "computer vision engineer\n",
            "cybersecurity engineer\n",
            "data engineer\n",
            "data science consultant\n",
            "data scientist\n",
            "database administrator\n",
            "database engineer\n",
            "deep learning engineer\n",
            "devops engineer\n",
            "electrical engineer\n",
            "embedded systems engineer\n",
            "flutter developer\n",
            "frontend developer\n",
            "full stack developer\n",
            "information security analyst\n",
            "infrastructure engineer\n",
            "ios developer\n",
            "java developer\n",
            "java web developer\n",
            "javascript developer\n",
            "jr. java developer\n",
            "kubernetes engineer\n",
            "machine learning engineer\n",
            "machine learning engineer intern\n",
            "mlops engineer\n",
            "mobile developer\n",
            "network and security engineer\n",
            "network security engineer\n",
            "nlp engineer\n",
            "node.js developer\n",
            "nosql developer\n",
            "operations manager\n",
            "penetration tester\n",
            "platform engineer\n",
            "project manager\n",
            "python api developer\n",
            "python developer\n",
            "python developer/analyst\n",
            "python restful api developer\n",
            "qa engineer\n",
            "react developer\n",
            "react native developer\n",
            "sap technical architect\n",
            "security engineer\n",
            "senior business analyst - rpa\n",
            "site reliability engineer\n",
            "software engineer\n",
            "software testing & automation engineer\n",
            "solutions architect\n",
            "sql developer\n",
            "systems engineer\n",
            "technical architect\n",
            "vue developer\n",
            "web developer\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "def extract_all_roles(path=\"final_clean_dataset.jsonl\"):\n",
        "    roles = set()\n",
        "    with open(path, \"r\") as f:\n",
        "        for line in f:\n",
        "            try:\n",
        "                obj = json.loads(line)\n",
        "                role = obj[\"output\"][\"role\"].strip().lower()\n",
        "                roles.add(role)\n",
        "            except:\n",
        "                pass\n",
        "    return sorted(roles)\n",
        "\n",
        "roles = extract_all_roles(\"final_clean_dataset.jsonl\")\n",
        "\n",
        "for r in roles:\n",
        "    print(r)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9j5aYuGvCBSu",
        "outputId": "c30f9a6c-b2dd-4a5b-812d-4a4bf1f2bf7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Final LoRA dataset saved → final_lora_dataset.jsonl\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "MASTER_SKILLS = {\n",
        "    \"adjunct faculty & data scientist\": {\n",
        "        \"junior\": [\"python\", \"pandas\", \"matplotlib\", \"sql\"],\n",
        "        \"mid\": [\"scikit-learn\", \"feature engineering\", \"numpy\", \"data preprocessing\"],\n",
        "        \"senior\": [\"machine learning pipelines\", \"model deployment\", \"data warehousing\", \"deep learning\"]\n",
        "    },\n",
        "\n",
        "    \"ai engineer\": {\n",
        "        \"junior\": [\"python\", \"numpy\", \"tensorflow basics\", \"data preprocessing\"],\n",
        "        \"mid\": [\"pytorch\", \"model optimization\", \"opencv\", \"transformers\"],\n",
        "        \"senior\": [\"distributed training\", \"model quantization\", \"ml pipelines\", \"reinforcement learning\"]\n",
        "    },\n",
        "\n",
        "    \"android developer\": {\n",
        "        \"junior\": [\"kotlin\", \"android studio\", \"xml layouts\", \"retrofit\"],\n",
        "        \"mid\": [\"room database\", \"coroutines\", \"jetpack components\", \"firebase\"],\n",
        "        \"senior\": [\"android architecture components\", \"jetpack compose\", \"modularization\", \"performance tuning\"]\n",
        "    },\n",
        "\n",
        "    \"angular developer\": {\n",
        "        \"junior\": [\"angular basics\", \"typescript\", \"html/css\", \"rxjs\"],\n",
        "        \"mid\": [\"angular routing\", \"ngrx\", \"rest integration\", \"form builder\"],\n",
        "        \"senior\": [\"state management\", \"lazy loading\", \"architecture patterns\", \"micro frontends\"]\n",
        "    },\n",
        "\n",
        "    \"automation engineer\": {\n",
        "        \"junior\": [\"python\", \"bash scripting\", \"webdriver\", \"selenium basics\"],\n",
        "        \"mid\": [\"jenkins pipelines\", \"api automation\", \"pytest\", \"docker\"],\n",
        "        \"senior\": [\"automation frameworks\", \"infrastructure automation\", \"kubernetes\", \"ci pipeline design\"]\n",
        "    },\n",
        "\n",
        "    \"backend developer\": {\n",
        "        \"junior\": [\"python\", \"django basics\", \"sql\", \"rest apis\"],\n",
        "        \"mid\": [\"postgresql\", \"redis\", \"api authentication\", \"fastapi\"],\n",
        "        \"senior\": [\"system design\", \"scalability patterns\", \"microservices\", \"docker orchestration\"]\n",
        "    },\n",
        "\n",
        "    \"blockchain developer\": {\n",
        "        \"junior\": [\"solidity\", \"ethereum basics\", \"web3.js\", \"smart contracts\"],\n",
        "        \"mid\": [\"nft standards\", \"truffle\", \"ganache\", \"contract testing\"],\n",
        "        \"senior\": [\"layer 2 scaling\", \"tokenomics\", \"protocol design\", \"security auditing\"]\n",
        "    },\n",
        "\n",
        "    \"cloud engineer\": {\n",
        "        \"junior\": [\"aws ec2\", \"s3\", \"linux\", \"iam basics\"],\n",
        "        \"mid\": [\"lambda\", \"cloudformation\", \"load balancers\", \"vpc networking\"],\n",
        "        \"senior\": [\"multi-cloud design\", \"infrastructure automation\", \"kubernetes clusters\", \"cost optimization\"]\n",
        "    },\n",
        "\n",
        "    \"cloud operations architect (devops)\": {\n",
        "        \"junior\": [\"docker\", \"linux\", \"git\", \"basic ci/cd\"],\n",
        "        \"mid\": [\"kubernetes\", \"jenkins\", \"aws services\", \"terraform\"],\n",
        "        \"senior\": [\"infrastructure architecture\", \"scalable pipelines\", \"multi-region deployments\", \"monitoring systems\"]\n",
        "    },\n",
        "\n",
        "    \"computer vision engineer\": {\n",
        "        \"junior\": [\"opencv\", \"numpy\", \"python\", \"image preprocessing\"],\n",
        "        \"mid\": [\"cnn models\", \"pytorch\", \"augmentation pipelines\", \"segmentation\"],\n",
        "        \"senior\": [\"large vision models\", \"3d vision\", \"real-time inference\", \"edge deployment\"]\n",
        "    },\n",
        "\n",
        "    \"cybersecurity engineer\": {\n",
        "        \"junior\": [\"wireshark\", \"linux security\", \"network scanning\", \"firewall basics\"],\n",
        "        \"mid\": [\"ids/ips\", \"penetration testing\", \"log analysis\", \"threat modeling\"],\n",
        "        \"senior\": [\"siem systems\", \"zero trust\", \"incident response\", \"security automation\"]\n",
        "    },\n",
        "\n",
        "    \"data engineer\": {\n",
        "        \"junior\": [\"python\", \"sql\", \"pandas\", \"etl basics\"],\n",
        "        \"mid\": [\"airflow\", \"spark\", \"bigquery\", \"data modeling\"],\n",
        "        \"senior\": [\"distributed systems\", \"data lake design\", \"pipeline optimization\", \"cloud data platforms\"]\n",
        "    },\n",
        "\n",
        "    \"data science consultant\": {\n",
        "        \"junior\": [\"python\", \"numpy\", \"eda\", \"sql\"],\n",
        "        \"mid\": [\"feature engineering\", \"model selection\", \"pandas\", \"time series\"],\n",
        "        \"senior\": [\"ml deployment\", \"business ml strategy\", \"optimization models\", \"large datasets\"]\n",
        "    },\n",
        "\n",
        "    \"data scientist\": {\n",
        "        \"junior\": [\"python\", \"pandas\", \"scikit-learn\", \"data cleaning\"],\n",
        "        \"mid\": [\"ml algorithms\", \"model tuning\", \"feature importance\", \"xgboost\"],\n",
        "        \"senior\": [\"ml architecture\", \"deep learning\", \"pipeline automation\", \"generative ai\"]\n",
        "    },\n",
        "\n",
        "    \"database administrator\": {\n",
        "        \"junior\": [\"mysql\", \"backup procedures\", \"sql queries\", \"indexes\"],\n",
        "        \"mid\": [\"postgresql\", \"performance tuning\", \"replication\", \"monitoring tools\"],\n",
        "        \"senior\": [\"sharding\", \"db security\", \"disaster recovery\", \"high availability\"]\n",
        "    },\n",
        "\n",
        "    \"database engineer\": {\n",
        "        \"junior\": [\"sql\", \"mysql basics\", \"schema design\", \"stored procedures\"],\n",
        "        \"mid\": [\"postgresql\", \"query optimization\", \"etl pipeline\", \"indexing strategies\"],\n",
        "        \"senior\": [\"distributed databases\", \"replication design\", \"data modeling\", \"scalable storage\"]\n",
        "    },\n",
        "\n",
        "    \"deep learning engineer\": {\n",
        "        \"junior\": [\"tensorflow\", \"numpy\", \"cnn basics\", \"python\"],\n",
        "        \"mid\": [\"pytorch\", \"transformers\", \"training optimization\", \"rnn models\"],\n",
        "        \"senior\": [\"distributed training\", \"large model fine-tuning\", \"mlops integration\", \"model optimization\"]\n",
        "    },\n",
        "\n",
        "    \"devops engineer\": {\n",
        "        \"junior\": [\"docker\", \"linux\", \"git\", \"basic ci/cd\"],\n",
        "        \"mid\": [\"kubernetes\", \"aws ec2\", \"jenkins\", \"terraform\"],\n",
        "        \"senior\": [\"scalable ci pipelines\", \"infrastructure design\", \"multi-cloud orchestration\", \"monitoring setup\"]\n",
        "    },\n",
        "\n",
        "    \"electrical engineer\": {\n",
        "        \"junior\": [\"matlab\", \"c programming\", \"circuit design\", \"pcb basics\"],\n",
        "        \"mid\": [\"fpga\", \"embedded c\", \"signal processing\", \"simulation tools\"],\n",
        "        \"senior\": [\"system integration\", \"hardware optimization\", \"power electronics\", \"embedded architecture\"]\n",
        "    },\n",
        "\n",
        "    \"embedded systems engineer\": {\n",
        "        \"junior\": [\"c\", \"embedded c\", \"microcontrollers\", \"uart/spi/i2c\"],\n",
        "        \"mid\": [\"rtos\", \"firmware debugging\", \"bootloaders\", \"embedded linux\"],\n",
        "        \"senior\": [\"system architecture\", \"board bring-up\", \"performance tuning\", \"hardware/software integration\"]\n",
        "    },\n",
        "\n",
        "    \"flutter developer\": {\n",
        "        \"junior\": [\"dart\", \"flutter widgets\", \"http client\", \"stateful widgets\"],\n",
        "        \"mid\": [\"provider\", \"bloc\", \"api integration\", \"firebase\"],\n",
        "        \"senior\": [\"custom renderers\", \"app architecture\", \"isolate optimization\", \"advanced state management\"]\n",
        "    },\n",
        "\n",
        "    \"frontend developer\": {\n",
        "        \"junior\": [\"html\", \"css\", \"javascript\", \"basic react\"],\n",
        "        \"mid\": [\"redux\", \"typescript\", \"api integration\", \"component architecture\"],\n",
        "        \"senior\": [\"frontend optimization\", \"micro frontends\", \"scalable design systems\", \"performance profiling\"]\n",
        "    },\n",
        "\n",
        "    \"full stack developer\": {\n",
        "        \"junior\": [\"javascript\", \"node.js\", \"html/css\", \"sql\"],\n",
        "        \"mid\": [\"express\", \"react\", \"rest apis\", \"postgresql\"],\n",
        "        \"senior\": [\"system design\", \"microservices\", \"cloud deployments\", \"scalable backend\"]\n",
        "    },\n",
        "\n",
        "    \"information security analyst\": {\n",
        "        \"junior\": [\"network basics\", \"firewall rules\", \"vulnerability scanning\", \"log analysis\"],\n",
        "        \"mid\": [\"ids/ips\", \"malware analysis\", \"incident triage\", \"forensics tools\"],\n",
        "        \"senior\": [\"security architecture\", \"threat hunting\", \"siem management\", \"zero trust design\"]\n",
        "    },\n",
        "\n",
        "    \"infrastructure engineer\": {\n",
        "        \"junior\": [\"linux\", \"bash scripting\", \"network basics\", \"docker\"],\n",
        "        \"mid\": [\"kubernetes\", \"load balancers\", \"terraform\", \"monitoring tools\"],\n",
        "        \"senior\": [\"infrastructure design\", \"multi-region networking\", \"system scalability\", \"cloud provisioning\"]\n",
        "    },\n",
        "\n",
        "    \"ios developer\": {\n",
        "        \"junior\": [\"swift\", \"xcode\", \"uikit\", \"storyboards\"],\n",
        "        \"mid\": [\"swiftui\", \"combine\", \"core data\", \"api integration\"],\n",
        "        \"senior\": [\"modular architecture\", \"performance profiling\", \"concurrency\", \"framework development\"]\n",
        "    },\n",
        "\n",
        "    \"java developer\": {\n",
        "        \"junior\": [\"java\", \"spring basics\", \"hibernate\", \"sql\"],\n",
        "        \"mid\": [\"spring boot\", \"rest apis\", \"junit\", \"kafka\"],\n",
        "        \"senior\": [\"microservices\", \"distributed systems\", \"system design\", \"cloud deployment\"]\n",
        "    },\n",
        "\n",
        "    \"java web developer\": {\n",
        "        \"junior\": [\"java\", \"servlets\", \"jsp\", \"mysql\"],\n",
        "        \"mid\": [\"spring mvc\", \"api development\", \"tomcat\", \"rest\"],\n",
        "        \"senior\": [\"spring boot microservices\", \"distributed design\", \"cloud packaging\", \"performance optimization\"]\n",
        "    },\n",
        "\n",
        "    \"javascript developer\": {\n",
        "        \"junior\": [\"javascript\", \"html/css\", \"dom manipulation\", \"fetch api\"],\n",
        "        \"mid\": [\"react\", \"typescript\", \"webpack\", \"api integration\"],\n",
        "        \"senior\": [\"frontend architecture\", \"performance tuning\", \"micro frontends\", \"state management\"]\n",
        "    },\n",
        "\n",
        "    \"jr. java developer\": {\n",
        "        \"junior\": [\"java\", \"junit\", \"jdbc\", \"basic spring\"],\n",
        "        \"mid\": [\"spring boot\", \"rest apis\", \"postgresql\", \"maven\"],\n",
        "        \"senior\": [\"microservices\", \"system design\", \"distributed architecture\", \"cloud deployment\"]\n",
        "    },\n",
        "\n",
        "    \"kubernetes engineer\": {\n",
        "        \"junior\": [\"docker\", \"kubernetes basics\", \"pods/services\", \"yaml configs\"],\n",
        "        \"mid\": [\"helm charts\", \"ingress\", \"k8s monitoring\", \"statefulsets\"],\n",
        "        \"senior\": [\"cluster architecture\", \"autoscaling\", \"service mesh\", \"advanced networking\"]\n",
        "    },\n",
        "\n",
        "    \"machine learning engineer\": {\n",
        "        \"junior\": [\"python\", \"numpy\", \"scikit-learn\", \"data preprocessing\"],\n",
        "        \"mid\": [\"pytorch\", \"tensorflow\", \"feature engineering\", \"ml pipelines\"],\n",
        "        \"senior\": [\"distributed training\", \"model optimization\", \"mlops\", \"large model tuning\"]\n",
        "    },\n",
        "\n",
        "    \"machine learning engineer intern\": {\n",
        "        \"junior\": [\"python\", \"numpy\", \"pandas\", \"basic ml models\"],\n",
        "        \"mid\": [\"data cleaning\", \"feature engineering\", \"scikit-learn\", \"model evaluation\"],\n",
        "        \"senior\": [\"advanced ml workflows\", \"deployment basics\", \"pytorch\", \"tensorflow\"]\n",
        "    },\n",
        "\n",
        "    \"mlops engineer\": {\n",
        "        \"junior\": [\"docker\", \"python\", \"linux\", \"git\"],\n",
        "        \"mid\": [\"airflow\", \"kubernetes\", \"mlflow\", \"jenkins\"],\n",
        "        \"senior\": [\"ml pipelines\", \"distributed training\", \"cloud ml platforms\", \"model monitoring\"]\n",
        "    },\n",
        "\n",
        "    \"mobile developer\": {\n",
        "        \"junior\": [\"kotlin\", \"swift\", \"rest apis\", \"ui layouts\"],\n",
        "        \"mid\": [\"flutter\", \"react native\", \"local databases\", \"firebase\"],\n",
        "        \"senior\": [\"multi-platform optimization\", \"app architecture\", \"performance profiling\", \"security hardening\"]\n",
        "    },\n",
        "\n",
        "    \"network and security engineer\": {\n",
        "        \"junior\": [\"subnetting\", \"firewalls\", \"routing basics\", \"linux networking\"],\n",
        "        \"mid\": [\"vpn\", \"ids/ips\", \"fortinet\", \"packet inspection\"],\n",
        "        \"senior\": [\"network architecture\", \"zero trust\", \"high availability design\", \"cloud networking\"]\n",
        "    },\n",
        "\n",
        "    \"network security engineer\": {\n",
        "        \"junior\": [\"vlan\", \"access lists\", \"tcp/ip basics\", \"wireshark\"],\n",
        "        \"mid\": [\"firewall rules\", \"ids/ips\", \"vpn configuration\", \"routing protocols\"],\n",
        "        \"senior\": [\"network hardening\", \"siem integration\", \"advanced firewalling\", \"security architecture\"]\n",
        "    },\n",
        "\n",
        "    \"nlp engineer\": {\n",
        "        \"junior\": [\"python\", \"nltk\", \"regex\", \"text preprocessing\"],\n",
        "        \"mid\": [\"transformers\", \"huggingface\", \"tokenization\", \"embeddings\"],\n",
        "        \"senior\": [\"llm fine-tuning\", \"retrieval pipelines\", \"model optimization\", \"deployment systems\"]\n",
        "    },\n",
        "\n",
        "    \"node.js developer\": {\n",
        "        \"junior\": [\"node.js\", \"express basics\", \"javascript\", \"mongo basics\"],\n",
        "        \"mid\": [\"jwt auth\", \"redis caching\", \"rest apis\", \"typescript\"],\n",
        "        \"senior\": [\"microservices\", \"message queues\", \"scalable server design\", \"cloud packaging\"]\n",
        "    },\n",
        "\n",
        "    \"nosql developer\": {\n",
        "        \"junior\": [\"mongodb\", \"redis basics\", \"document modeling\", \"queries\"],\n",
        "        \"mid\": [\"replication\", \"sharding basics\", \"cassandra\", \"indexing\"],\n",
        "        \"senior\": [\"distributed databases\", \"performance tuning\", \"cluster design\", \"storage optimization\"]\n",
        "    },\n",
        "\n",
        "    \"operations manager\": {\n",
        "        \"junior\": [\"excel\", \"sql basics\", \"dashboards\", \"report automation\"],\n",
        "        \"mid\": [\"data workflows\", \"api integrations\", \"python scripts\", \"etl basics\"],\n",
        "        \"senior\": [\"system automation\", \"infrastructure monitoring\", \"cloud tools\", \"process optimization\"]\n",
        "    },\n",
        "\n",
        "    \"penetration tester\": {\n",
        "        \"junior\": [\"nmap\", \"burpsuite basics\", \"linux\", \"recon tools\"],\n",
        "        \"mid\": [\"metasploit\", \"web exploitation\", \"network attacks\", \"password auditing\"],\n",
        "        \"senior\": [\"red teaming\", \"post exploitation\", \"exploit writing\", \"advanced security testing\"]\n",
        "    },\n",
        "\n",
        "    \"platform engineer\": {\n",
        "        \"junior\": [\"docker\", \"linux\", \"github actions\", \"rest apis\"],\n",
        "        \"mid\": [\"kubernetes\", \"terraform\", \"monitoring tools\", \"network configs\"],\n",
        "        \"senior\": [\"platform architecture\", \"scalable infra\", \"multi-cloud design\", \"advanced automation\"]\n",
        "    },\n",
        "\n",
        "    \"project manager\": {\n",
        "        \"junior\": [\"jira setup\", \"sql basics\", \"api understanding\", \"excel\"],\n",
        "        \"mid\": [\"kpi tracking\", \"workflow automation\", \"integration tools\", \"dashboards\"],\n",
        "        \"senior\": [\"system oversight\", \"architecture understanding\", \"deployment planning\", \"release pipelines\"]\n",
        "    },\n",
        "\n",
        "    \"python api developer\": {\n",
        "        \"junior\": [\"python\", \"flask basics\", \"rest apis\", \"json handling\"],\n",
        "        \"mid\": [\"fastapi\", \"api authentication\", \"postgresql\", \"redis\"],\n",
        "        \"senior\": [\"microservices\", \"scalable apis\", \"cloud deployments\", \"performance tuning\"]\n",
        "    },\n",
        "\n",
        "    \"python developer\": {\n",
        "        \"junior\": [\"python\", \"django basics\", \"sqlite\", \"rest integration\"],\n",
        "        \"mid\": [\"django orm\", \"asgi\", \"postgresql\", \"celery\"],\n",
        "        \"senior\": [\"distributed tasks\", \"cloud packaging\", \"scalable backend\", \"system design\"]\n",
        "    },\n",
        "\n",
        "    \"python developer/analyst\": {\n",
        "        \"junior\": [\"python\", \"pandas\", \"matplotlib\", \"basic sql\"],\n",
        "        \"mid\": [\"etl scripts\", \"api consumption\", \"data modeling\", \"numpy\"],\n",
        "        \"senior\": [\"pipeline automation\", \"cloud analytics\", \"large dataset handling\", \"ml integration\"]\n",
        "    },\n",
        "\n",
        "    \"python restful api developer\": {\n",
        "        \"junior\": [\"python\", \"flask\", \"json serialization\", \"sqlite\"],\n",
        "        \"mid\": [\"fastapi\", \"api routing\", \"postgresql\", \"jwt auth\"],\n",
        "        \"senior\": [\"microservices\", \"load balancing\", \"cloud deployments\", \"api optimization\"]\n",
        "    },\n",
        "\n",
        "    \"qa engineer\": {\n",
        "        \"junior\": [\"selenium\", \"webdriver\", \"test cases\", \"pytest basics\"],\n",
        "        \"mid\": [\"api testing\", \"automation frameworks\", \"jenkins\", \"postman\"],\n",
        "        \"senior\": [\"performance testing\", \"test architecture\", \"load testing\", \"ci automation\"]\n",
        "    },\n",
        "\n",
        "    \"react developer\": {\n",
        "        \"junior\": [\"react basics\", \"javascript\", \"html/css\", \"axios\"],\n",
        "        \"mid\": [\"redux\", \"component architecture\", \"typescript\", \"api integration\"],\n",
        "        \"senior\": [\"scalable frontend\", \"performance tuning\", \"micro frontends\", \"state optimization\"]\n",
        "    },\n",
        "\n",
        "    \"react native developer\": {\n",
        "        \"junior\": [\"react native basics\", \"javascript\", \"components\", \"api usage\"],\n",
        "        \"mid\": [\"navigation\", \"state management\", \"typescript\", \"local storage\"],\n",
        "        \"senior\": [\"native modules\", \"performance tuning\", \"app architecture\", \"multi-platform support\"]\n",
        "    },\n",
        "\n",
        "    \"sap technical architect\": {\n",
        "        \"junior\": [\"abap basics\", \"sap gui\", \"sql\", \"report creation\"],\n",
        "        \"mid\": [\"sap hana\", \"data modeling\", \"integration\", \"bapi\"],\n",
        "        \"senior\": [\"sap landscape design\", \"performance tuning\", \"cloud integration\", \"architecture planning\"]\n",
        "    },\n",
        "\n",
        "    \"security engineer\": {\n",
        "        \"junior\": [\"linux\", \"tcp/ip\", \"firewalls\", \"wireshark\"],\n",
        "        \"mid\": [\"ids/ips\", \"threat detection\", \"log analysis\", \"network monitoring\"],\n",
        "        \"senior\": [\"security design\", \"siem systems\", \"incident response\", \"zero trust\"]\n",
        "    },\n",
        "\n",
        "    \"senior business analyst - rpa\": {\n",
        "        \"junior\": [\"excel\", \"sql basics\", \"process mapping\", \"automation basics\"],\n",
        "        \"mid\": [\"uipath\", \"api consumption\", \"workflow rules\", \"bot design\"],\n",
        "        \"senior\": [\"automation architecture\", \"rpa scaling\", \"cloud rpa\", \"advanced workflows\"]\n",
        "    },\n",
        "\n",
        "    \"site reliability engineer\": {\n",
        "        \"junior\": [\"linux\", \"docker\", \"basic monitoring\", \"bash\"],\n",
        "        \"mid\": [\"kubernetes\", \"prometheus\", \"grafana\", \"ci/cd\"],\n",
        "        \"senior\": [\"scalable systems\", \"incident automation\", \"observability design\", \"chaos testing\"]\n",
        "    },\n",
        "\n",
        "    \"software engineer\": {\n",
        "        \"junior\": [\"python\", \"rest apis\", \"sql\", \"javascript\"],\n",
        "        \"mid\": [\"react\", \"django\", \"node.js\", \"postgresql\"],\n",
        "        \"senior\": [\"system design\", \"microservices\", \"cloud deployments\", \"optimization\"]\n",
        "    },\n",
        "\n",
        "    \"software testing & automation engineer\": {\n",
        "        \"junior\": [\"selenium\", \"python\", \"test cases\", \"webdriver\"],\n",
        "        \"mid\": [\"api automation\", \"pytest\", \"jenkins\", \"postman\"],\n",
        "        \"senior\": [\"framework design\", \"performance testing\", \"ci automation\", \"scalable tests\"]\n",
        "    },\n",
        "\n",
        "    \"solutions architect\": {\n",
        "        \"junior\": [\"api basics\", \"databases\", \"python\", \"cloud fundamentals\"],\n",
        "        \"mid\": [\"system integration\", \"distributed apps\", \"rest apis\", \"deployment\"],\n",
        "        \"senior\": [\"system design\", \"microservices\", \"cloud architecture\", \"scalability planning\"]\n",
        "    },\n",
        "\n",
        "    \"sql developer\": {\n",
        "        \"junior\": [\"mysql\", \"joins\", \"indexes\", \"queries\"],\n",
        "        \"mid\": [\"postgresql\", \"procedures\", \"optimization\", \"data modeling\"],\n",
        "        \"senior\": [\"distributed sql\", \"query tuning\", \"warehouse design\", \"pipeline optimization\"]\n",
        "    },\n",
        "\n",
        "    \"systems engineer\": {\n",
        "        \"junior\": [\"linux\", \"bash\", \"network basics\", \"docker\"],\n",
        "        \"mid\": [\"kubernetes\", \"vmware\", \"monitoring tools\", \"load balancers\"],\n",
        "        \"senior\": [\"system design\", \"cloud infra\", \"scalable architectures\", \"security hardening\"]\n",
        "    },\n",
        "\n",
        "    \"technical architect\": {\n",
        "        \"junior\": [\"basic design patterns\", \"api concepts\", \"databases\", \"python\"],\n",
        "        \"mid\": [\"system design\", \"microservices\", \"api architecture\", \"cloud basics\"],\n",
        "        \"senior\": [\"enterprise architecture\", \"cloud systems\", \"scalable design\", \"integration design\"]\n",
        "    },\n",
        "\n",
        "    \"vue developer\": {\n",
        "        \"junior\": [\"vue basics\", \"javascript\", \"html/css\", \"vuex\"],\n",
        "        \"mid\": [\"component design\", \"routing\", \"api integration\", \"vuetify\"],\n",
        "        \"senior\": [\"scalable apps\", \"performance tuning\", \"micro frontends\", \"architecture patterns\"]\n",
        "    },\n",
        "\n",
        "    \"web developer\": {\n",
        "        \"junior\": [\"html\", \"css\", \"javascript\", \"bootstrap\"],\n",
        "        \"mid\": [\"rest apis\", \"react\", \"node.js\", \"api integration\"],\n",
        "        \"senior\": [\"frontend optimization\", \"backend integration\", \"scalable systems\", \"deployment pipelines\"]\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "def get_level_from_experience(exp_str):\n",
        "\n",
        "    years = int(exp_str.split()[0])\n",
        "\n",
        "    if years <= 2:\n",
        "        return \"junior\"\n",
        "    elif years <= 5:\n",
        "        return \"mid\"\n",
        "    else:\n",
        "        return \"senior\"\n",
        "\n",
        "\n",
        "\n",
        "def filter_and_supplement(role, level, raw_keywords):\n",
        "    role_key = role.lower().strip()\n",
        "\n",
        "    if role_key not in MASTER_SKILLS:\n",
        "        \n",
        "        return raw_keywords[:10]\n",
        "\n",
        "    master = MASTER_SKILLS[role_key][level]\n",
        "    master_lower = [m.lower() for m in master]\n",
        "\n",
        "    \n",
        "    filtered = [kw for kw in raw_keywords if kw.lower() in master_lower]\n",
        "\n",
        " \n",
        "    missing = [kw for kw in master if kw.lower() not in [x.lower() for x in filtered]]\n",
        "\n",
        "   \n",
        "    supplement = missing[:4]\n",
        "\n",
        "    final_list = filtered + supplement\n",
        "\n",
        "    seen = set()\n",
        "    cleaned = []\n",
        "    for kw in final_list:\n",
        "        if kw.lower() not in seen:\n",
        "            cleaned.append(kw)\n",
        "            seen.add(kw.lower())\n",
        "\n",
        "    return cleaned[:10]  \n",
        "\n",
        "\n",
        "\n",
        "def build_final_dataset(input_path=\"final_clean_dataset.jsonl\",\n",
        "                        output_path=\"final_lora_dataset.jsonl\"):\n",
        "\n",
        "    with open(input_path, \"r\") as infile, open(output_path, \"w\") as outfile:\n",
        "\n",
        "        for line in infile:\n",
        "            obj = json.loads(line)\n",
        "\n",
        "            role = obj[\"output\"][\"role\"]\n",
        "            exp = obj[\"output\"][\"experience\"]\n",
        "            raw_keywords = obj[\"output\"][\"keywords\"]\n",
        "\n",
        "            \n",
        "            level = get_level_from_experience(exp)\n",
        "\n",
        "           \n",
        "            final_keywords = filter_and_supplement(role, level, raw_keywords)\n",
        "\n",
        "           \n",
        "            cleaned = {\n",
        "                \"input\": obj[\"input\"],\n",
        "                \"output\": {\n",
        "                    \"role\": role,\n",
        "                    \"experience\": exp,\n",
        "                    \"keywords\": final_keywords\n",
        "                }\n",
        "            }\n",
        "\n",
        "            outfile.write(json.dumps(cleaned) + \"\\n\")\n",
        "\n",
        "    print(\"Final LoRA dataset saved →\", output_path)\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    build_final_dataset()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juZA5HA3Osms",
        "outputId": "753f43d5-5614-4cd5-bf2d-8a84dfca21b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error on line 1: Expecting property name enclosed in double quotes: line 2 column 1 (char 2)\n",
            "Line content: {\n",
            "\n"
          ]
        }
      ],
      "source": [
        "with open(\"final_lora_dataset.jsonl\") as f:\n",
        "    for i, line in enumerate(f, start=1):\n",
        "        try:\n",
        "            json.loads(line)\n",
        "        except Exception as e:\n",
        "            print(f\"Error on line {i}: {e}\")\n",
        "            print(\"Line content:\", line)\n",
        "            break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHMNxrVYOvgj",
        "outputId": "be78ccbb-2b88-43ca-c210-b9fb80dd1410"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading dataset...\n",
            "Extracting JSON objects (brace counting)...\n",
            "Found 324 JSON objects.\n",
            "\n",
            "Conversion complete!\n",
            "✔ Valid objects converted: 324\n",
            "✖ Invalid objects skipped: 0\n",
            "Output file created: lora_messages_dataset.jsonl\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "INPUT_PATH = \"final_lora_dataset.jsonl\"\n",
        "OUTPUT_PATH = \"lora_messages_dataset.jsonl\"\n",
        "\n",
        "\n",
        "def extract_json_objects(text):\n",
        "   \n",
        "    objs = []\n",
        "    brace_count = 0\n",
        "    current = []\n",
        "\n",
        "    for ch in text:\n",
        "        if ch == '{':\n",
        "            brace_count += 1\n",
        "\n",
        "        if brace_count > 0:\n",
        "            current.append(ch)\n",
        "\n",
        "        if ch == '}':\n",
        "            brace_count -= 1\n",
        "            if brace_count == 0:\n",
        "                \n",
        "                obj_text = ''.join(current)\n",
        "                objs.append(obj_text)\n",
        "                current = []\n",
        "\n",
        "    return objs\n",
        "\n",
        "\n",
        "def build_assistant_text(output_obj):\n",
        "    role = output_obj.get(\"role\", \"\")\n",
        "    experience = output_obj.get(\"experience\", \"\")\n",
        "    keywords = output_obj.get(\"keywords\", [])\n",
        "    return (\n",
        "        f\"role: {role}\\n\"\n",
        "        f\"experience: {experience}\\n\"\n",
        "        f\"keywords: {', '.join(keywords)}\"\n",
        "    )\n",
        "\n",
        "\n",
        "def convert_dataset():\n",
        "    print(\"Reading dataset...\")\n",
        "    with open(INPUT_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "        raw = f.read()\n",
        "\n",
        "    print(\"Extracting JSON objects (brace counting)...\")\n",
        "    objs = extract_json_objects(raw)\n",
        "    print(f\"Found {len(objs)} JSON objects.\")\n",
        "\n",
        "    out = open(OUTPUT_PATH, \"w\", encoding=\"utf-8\")\n",
        "    count = 0\n",
        "    skipped = 0\n",
        "\n",
        "    for obj_text in objs:\n",
        "        try:\n",
        "            obj = json.loads(obj_text)\n",
        "        except Exception as e:\n",
        "            skipped += 1\n",
        "            continue\n",
        "\n",
        "        user_input = obj.get(\"input\", \"\")\n",
        "        output_obj = obj.get(\"output\", {})\n",
        "        assistant_text = build_assistant_text(output_obj)\n",
        "\n",
        "        chat = {\n",
        "            \"messages\": [\n",
        "                {\"role\": \"user\", \"content\": user_input},\n",
        "                {\"role\": \"assistant\", \"content\": assistant_text}\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        out.write(json.dumps(chat) + \"\\n\")\n",
        "        count += 1\n",
        "\n",
        "    out.close()\n",
        "\n",
        "    print(\"\\nConversion complete!\")\n",
        "    print(f\"✔ Valid objects converted: {count}\")\n",
        "    print(f\"✖ Invalid objects skipped: {skipped}\")\n",
        "    print(f\"Output file created: {OUTPUT_PATH}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    convert_dataset()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
